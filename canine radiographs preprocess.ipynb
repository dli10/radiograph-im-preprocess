{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "intensive-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'data/all/test/ap_mvvd/339952_DV_og.jpeg'\n",
    "\n",
    "img_arr = cv2.imread(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-durham",
   "metadata": {},
   "source": [
    "Below is image preprocessing code to make sure all the images are cropped and formatted in the same way. Note that this code does not iterate through all the images and will only preprocess one image at a time. \n",
    "\n",
    "The images run through this code are radiographs that have text labels on the top and bottom of the images, so those are removed by cropping 20 pixels from the left and right and 50 pixels from the top and bottom. Then, each image is cropped to a square around the center of the image. There may be benefits to cropping each image individually to ensure each image includes the area of interest, but as I am not an expert in analyzing radiographs so I decided to crop based on the center of each image. The last part of the code ensures that all the images are in an rgb format as they will be further processed using other code, which requires the images to be in rgb format. If the images are already in rgb format, they will not need to be converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image dimensions\n",
    "height, width, color = img_arr.shape\n",
    "\n",
    "# crop border 20 from left/right and 50 from top/bottom\n",
    "x1 = [20, 50]  # upper left hand crop point\n",
    "y1 = [width - 20, height - 50]  # lower right hand crop point\n",
    "\n",
    "crop1 = img_arr[x1[1]:y1[1], x1[0]:y1[0], 0:color]\n",
    "\n",
    "# crop to square\n",
    "height, width, color = crop1.shape  # new cropped dimensions\n",
    "\n",
    "if width > height:\n",
    "    diff = int((width - height)/2)\n",
    "    x2 = [diff, 0]  # upper left hand crop point\n",
    "    y2 = [width - diff, height]  # bottom right hand crop point\n",
    "    crop2 = crop1[x2[1]:y2[1], x2[0]:y2[0], 0:color]  # creates cropped square image\n",
    "elif height > width:\n",
    "    diff = int((height - width)/2)\n",
    "    x2 = [0, diff]  # upper left hand crop point\n",
    "    y2 = [width, height - diff]  # bottom right hand crop point\n",
    "    crop2 = crop1[x2[1]:y2[1], x2[0]:y2[0], 0:color]  # creates cropped square image\n",
    "else:\n",
    "    crop2 = crop1\n",
    "\n",
    "# ensure image is rgb\n",
    "if crop2.shape[2] == 3:\n",
    "    img_arr = crop2  # no need to convert if image is already rgb\n",
    "else:\n",
    "    img_arr = cv2.cvtColor(crop2,cv2.COLOR_GRAY2RGB)  # convert to rgb if image is grayscale"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
